{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cee6827",
   "metadata": {},
   "source": [
    "# Twitter Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc87907",
   "metadata": {},
   "source": [
    "By: Lluna Sanz Montrull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e458d0",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aed4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=d7d4c9d5cd6854ee6cb501f3c5bcf707d794f40d8ecde8e362cf24905d51d441\n",
      "  Stored in directory: c:\\users\\amaia\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "# Install Libraries\n",
    "# !pip install textblob\n",
    "# !pip install tweepy\n",
    "# !pip install pycountry\n",
    "# !pip install wordcloud\n",
    "# !pip install STOPWORDS\n",
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fc66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import tweepy\n",
    "\n",
    "from langdetect import detect\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815a2ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (Temp/ipykernel_4448/3792818801.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\amaia\\AppData\\Local\\Temp/ipykernel_4448/3792818801.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    consumerKey = “Type your consumer key here”\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# Authentication\n",
    "\n",
    "consumerKey = “Type your consumer key here”\n",
    "consumerSecret = “Type your consumer secret here”\n",
    "accessToken = “Type your access token here”\n",
    "accessTokenSecret = “Type your access token secret here”\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole)\n",
    "\n",
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input(\"Please enter how many tweets to analyze: \"))\n",
    "\n",
    "tweets = tweepy.Cursor(api.search, q=keyword).items(noOfTweet)\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "\n",
    "for tweet in tweets:\n",
    "    #print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score[‘neg’]\n",
    "    neu = score[‘neu’]\n",
    "    pos = score[‘pos’]\n",
    "    comp = score[‘compound’]\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    \n",
    "    if neg > pos:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "        \n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "        \n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "        \n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15651d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \", len(tweet_list))\n",
    "print(\"positive number: \", len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \", len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06847f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating PieCart\n",
    "\n",
    "labels = ['Positive ['+str(positive)+'%]', 'Neutral['+str(neutral)+'%]','Negative['+str(negative)+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for keyword= \"+keyword+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c15efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82504fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f07662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text (RT, Punctuation etc)\n",
    "\n",
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[“text”] = tw_list[0]\n",
    "\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: '',\" \", x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0–9]+)|([⁰-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Negative, Positive, Neutral and Compound values\n",
    "\n",
    "tw_list[[‘polarity’, ‘subjectivity’]] = tw_list[‘text’].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "\n",
    "for index, row in tw_list[‘text’].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score[‘neg’]\n",
    "    neu = score[‘neu’]\n",
    "    pos = score[‘pos’]\n",
    "    comp = score[‘compound’]\n",
    "    if neg > pos:\n",
    "        tw_list.loc[index, ‘sentiment’] = “negative”\n",
    "    elif pos > neg:\n",
    "        tw_list.loc[index, ‘sentiment’] = “positive”\n",
    "    else:\n",
    "        tw_list.loc[index, ‘sentiment’] = “neutral”\n",
    "        tw_list.loc[index, ‘neg’] = neg\n",
    "        tw_list.loc[index, ‘neu’] = neu\n",
    "        tw_list.loc[index, ‘pos’] = pos\n",
    "        tw_list.loc[index, ‘compound’] = comp\n",
    "\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db389d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "\n",
    "tw_list_negative = tw_list[tw_list[“sentiment”]==”negative”]\n",
    "tw_list_positive = tw_list[tw_list[“sentiment”]==”positive”]\n",
    "tw_list_neutral = tw_list[tw_list[“sentiment”]==”neutral”]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb579900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=[‘Total’,’Percentage’])\n",
    "\n",
    "#Count_values for sentiment\n",
    "count_values_in_column(tw_list,”sentiment”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for Pie Chart\n",
    "pichart = count_values_in_column(tw_list,”sentiment”)\n",
    "names= pc.index\n",
    "size=pc[“Percentage”]\n",
    " \n",
    "# Create a circle for the center of the plot\n",
    "my_circle=plt.Circle( (0,0), 0.7, color=’white’)\n",
    "plt.pie(size, labels=names, colors=[‘green’,’blue’,’red’])\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea608d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Create Wordcloud\n",
    "def create_wordcloud(text):\n",
    "    mask = np.array(Image.open(“cloud.png”))\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wc = WordCloud(background_color=”white”, mask = mask, max_words=3000, stopwords=stopwords, repeat=True)\n",
    "    wc.generate(str(text))\n",
    "    wc.to_file(“wc.png”)\n",
    "    print(“Word Cloud Saved Successfully”)\n",
    "    path=”wc.png”\n",
    "    display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e855f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for all tweets\n",
    "create_wordcloud(tw_list[“text”].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for positive sentiment\n",
    "create_wordcloud(tw_list_positive[“text”].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e368d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for negative sentiment\n",
    "create_wordcloud(tw_list_negative[“text”].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating tweet’s lenght and word count\n",
    "tw_list[‘text_len’] = tw_list[‘text’].astype(str).apply(len)\n",
    "tw_list[‘text_word_count’] = tw_list[‘text’].apply(lambda x: len(str(x).split()))\n",
    "round(pd.DataFrame(tw_list.groupby(\"sentiment\").text_len.mean()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.DataFrame(tw_list.groupby(“sentiment”).text_word_count.mean()),2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
